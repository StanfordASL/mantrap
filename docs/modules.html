
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Objective and Constraint Modules &#8212; mantrap 0.1 documentation</title>
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Attention Modules" href="attention.html" />
    <link rel="prev" title="Solver" href="solver.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head><body>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="attention.html" title="Attention Modules"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="solver.html" title="Solver"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">mantrap 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Objective and Constraint Modules</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="objective-and-constraint-modules">
<h1>Objective and Constraint Modules<a class="headerlink" href="#objective-and-constraint-modules" title="Permalink to this headline">¶</a></h1>
<div class="section" id="base-optimization-modules-abstract">
<h2>Base Optimization Modules (abstract)<a class="headerlink" href="#base-optimization-modules-abstract" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-mantrap.modules.base.optimization_module">
<span id="base-class"></span><h3>Base class<a class="headerlink" href="#module-mantrap.modules.base.optimization_module" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.base.optimization_module.</code><code class="sig-name descname">OptimizationModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">has_slack</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">slack_weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_constraint">
<code class="sig-name descname">compute_constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine internal constraints + slack constraints.</p>
<p>Compute internal constraints and convert them to equality constraints by updating and adding the
slack variables. Then add further constraints for the slack variables themselves (&gt;= 0).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_gradient_analytically">
<code class="sig-name descname">compute_gradient_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_gradient_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective gradient vector analytically.</p>
<p>While the gradient vector of the objective can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main gradient() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>When no analytical solution is defined (or too hard to determine) return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_gradient_auto_grad">
<em class="property">static </em><code class="sig-name descname">compute_gradient_auto_grad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_gradient_auto_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute derivative of x with respect to grad_wrt.</p>
<p>Compute the gradient/jacobian/etc. of some vector x with respect to some tensor <cite>grad_wrt</cite>
using the PyTorch autograd, automatic differentiation package. Here we assume that both are
connected by some computational graph (PyTorch graph) that can be used for differentiation.</p>
<p>A comment about multiprocessing: Computing the gradients in parallel would be a good match
for multiple processing, since it is fairly independent from each other, given the shared
memory of the computation graph.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>

<span class="n">mp</span><span class="o">.</span><span class="n">set_start_method</span><span class="p">(</span><span class="s1">&#39;spawn&#39;</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
<span class="n">grad_wrt</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
<span class="n">gradient</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">grad_wrt_i</span><span class="p">):</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">grad_wrt</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

<span class="n">processes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i_process</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_process</span><span class="p">],</span> <span class="n">grad_wrt</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">processes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
    <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
<p>Here the torch.multiprocessing library is used to compute the gradient over the whole tensor x in
multiple parallel processes. Therefore the tensors of both x and grad_wrt are shared over all
processes using the <cite>.share_memory()</cite> method and all processes are launched with a different
element of the tensor x. However as shown below sharing a computation graph, i.e. tensors that
require a gradient, being attached to this graph, over multiple processes is not supported in
PyTorch and therefore not possible.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reduce_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cowardly refusing to serialize non-leaf tensor which requires_grad, &quot;</span>
                           <span class="s2">&quot;since autograd does not support crossing process boundaries.  &quot;</span>
                           <span class="s2">&quot;If you just want to transfer the data, call detach() on the tensor &quot;</span>
                           <span class="s2">&quot;before serializing (e.g., putting it on the queue).&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>To avoid this issue, the full computation graph would have to be re-built for every single element
of x, which would create a lot of overhead due to repeated computations (as well as being quite not
general and unreadable due to nesting instead of batching) and therefore not accelerate the computations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – gradient input flat vector.</p></li>
<li><p><strong>grad_wrt</strong> – tensor with respect to gradients should be computed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>flattened gradient tensor (x.size * grad_wrt.size)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_jacobian_analytically">
<code class="sig-name descname">compute_jacobian_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_jacobian_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Jacobian matrix analytically.</p>
<p>While the Jacobian matrix of the constraint can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main jacobian() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>When no analytical solution is defined (or too hard to determine) return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_objective">
<code class="sig-name descname">compute_objective</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine internal objective value + slack variables.</p>
<p>Add slack based part of objective function. The value of the slack variable can only be
updated if the constraints have been computed before. However using general optimization
frameworks we cannot enforce the order to method calls, therefore to be surely synced
we have to compute the constraints here first (!).
Add the slack-based objective if the constraint is violated, otherwise add zero (since
a constraint should not be optimised, just be feasible). The large <cite>slack_weight</cite> will
thereby force the optimiser to make some decision to become feasible again.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_violation">
<code class="sig-name descname">compute_violation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_violation" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint violation based on some input ego trajectory and ado ids list.</p>
<p>The violation is the amount how much the solution state is inside the constraint active region.
When the constraint is not active, then the violation is zero. The calculation is based on the last
(cached) evaluation of the constraint function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.compute_violation_internal">
<code class="sig-name descname">compute_violation_internal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.compute_violation_internal" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint violation, i.e. how much the internal state is inside the constraint active region.
When the constraint is not active, then the violation is zero. The calculation is based on the last (cached)
evaluation of the constraint function.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.constraint">
<code class="sig-name descname">constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint value for passed ego trajectory by calling the internal <cite>compute()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.constraint_core">
<em class="property">abstract </em><code class="sig-name descname">constraint_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.constraint_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint value core method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.constraint_limits">
<code class="sig-name descname">constraint_limits</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">, </span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.constraint_limits" title="Permalink to this definition">¶</a></dt>
<dd><p>Lower and upper bounds for constraint values.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine gradient vector for passed ego trajectory. Therefore determine the objective value by
calling the internal <cite>compute()</cite> method and en passant build a computation graph. Then using the pytorch
auto-grad library compute the gradient vector through the previously built computation graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.gradient_condition">
<em class="property">abstract </em><code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.jacobian">
<code class="sig-name descname">jacobian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.jacobian" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine jacobian matrix for passed ego trajectory.</p>
<p>Therefore at first check whether an analytical solution is defined, if not determine the constraint values
by calling the internal <cite>compute()</cite> method and en passant build a computation graph. Then using the PyTorch
autograd library compute the jacobian matrix based on the constraints computation graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.objective">
<code class="sig-name descname">objective</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value for passed ego trajectory by calling the internal <cite>compute()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.optimization_module.OptimizationModule.objective_core">
<em class="property">abstract </em><code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.optimization_module.OptimizationModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>The objective value should be returned either as PyTorch tensor or <cite>None</cite>. It cannot be simplified as
floating point number directly, as next to its value it is important to return the gradient function,
when computing its gradient. When the objective is not defined, simply return <cite>None</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mantrap.modules.base.pure_objective">
<span id="pure-objective"></span><h3>Pure objective<a class="headerlink" href="#module-mantrap.modules.base.pure_objective" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.base.pure_objective.PureObjectiveModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.base.pure_objective.</code><code class="sig-name descname">PureObjectiveModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.base.pure_objective.PureObjectiveModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Pure constraint module class.</p>
<p>For an unified and general implementation of objective and constraint function modules, this superclass
implements methods for computing both, either analytically or numerically based on the PyTorch autograd
package. Thereby all objective and constraint computations should be purely based on the robot’s (ego)
trajectory, as well as the possibility to perform further roll-outs in a given simulation environment.</p>
<p>The <cite>PureConstraintModule</cite> implements the general optimization module as pure constraint module, i.e.
for hard constraints without any inter-connection to the objective function.</p>
<dl class="py method">
<dt id="mantrap.modules.base.pure_objective.PureObjectiveModule.compute_jacobian_analytically">
<code class="sig-name descname">compute_jacobian_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.pure_objective.PureObjectiveModule.compute_jacobian_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Jacobian matrix analytically.</p>
<p>While the Jacobian matrix of the constraint can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main jacobian() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>When no analytical solution is defined (or too hard to determine) return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.pure_objective.PureObjectiveModule.constraint_core">
<code class="sig-name descname">constraint_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.pure_objective.PureObjectiveModule.constraint_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Returning <cite>None</cite> as an constraint automatically ends constraint and jacobian computation
and returns default values (empty numpy array).</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.pure_objective.PureObjectiveModule.constraint_limits">
<code class="sig-name descname">constraint_limits</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">, </span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.pure_objective.PureObjectiveModule.constraint_limits" title="Permalink to this definition">¶</a></dt>
<dd><p>Lower and upper bounds for constraint values.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mantrap.modules.base.pure_constraint">
<span id="pure-constraint"></span><h3>Pure constraint<a class="headerlink" href="#module-mantrap.modules.base.pure_constraint" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.base.pure_constraint.PureConstraintModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.base.pure_constraint.</code><code class="sig-name descname">PureConstraintModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.base.pure_constraint.PureConstraintModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Pure constraint module class.</p>
<p>For an unified and general implementation of objective and constraint function modules, this superclass
implements methods for computing both, either analytically or numerically based on the PyTorch autograd
package. Thereby all objective and constraint computations should be purely based on the robot’s (ego)
trajectory, as well as the possibility to perform further roll-outs in a given simulation environment.</p>
<p>The <cite>PureConstraintModule</cite> implements the general optimization module as pure constraint module, i.e.
for hard constraints without any inter-connection to the objective function.</p>
<dl class="py method">
<dt id="mantrap.modules.base.pure_constraint.PureConstraintModule.compute_gradient_analytically">
<code class="sig-name descname">compute_gradient_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.pure_constraint.PureConstraintModule.compute_gradient_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective gradient vector analytically.</p>
<p>While the gradient vector of the objective can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main gradient() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>When no analytical solution is defined (or too hard to determine) return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.base.pure_constraint.PureConstraintModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.base.pure_constraint.PureConstraintModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Returning <cite>None</cite> as an objective automatically ends objective and gradient computation
and returns default values (zero).</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="goal-driven-objectives">
<h2>Goal-Driven Objectives<a class="headerlink" href="#goal-driven-objectives" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-mantrap.modules.goal_norm">
<span id="goal-norm"></span><h3>Goal-Norm<a class="headerlink" href="#module-mantrap.modules.goal_norm" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.goal_norm.GoalNormModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.goal_norm.</code><code class="sig-name descname">GoalNormModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">goal</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">optimize_speed</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.5</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unsued</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.goal_norm.GoalNormModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Objective based on goal distance of every point of planned robot trajectory.</p>
<p>Next to avoiding interaction with other agents the robot should reach the goal state in a finite amount of
time. Therefore the distance of every trajectory point to the goal state is taken to account, which is
minimized the faster the robot gets to the goal.</p>
<div class="math notranslate nohighlight">
\[objective = 1/T \sum_{T} (pos_t - goal)^2\]</div>
<p>However, it is more important for the last rather than the first trajectory points to be close to the goal.
Using some strictly-increasing distribution to weight the importance of the distance at every point in time
did not lead to the expect result, while complicating the optimization. When we want to trade-off the
goal cost with other cost, simply adapting its weight is sufficient as well.</p>
<p>Additionally a cost for the velocity at the goal state can be included in this objective, a cost for non-zero
velocity to be exact. This cost is weighted continuously based on the distance to the goal, i.e. the closer
the a large speed (= velocity L2 norm) occurs, the higher its cost.</p>
<div class="math notranslate nohighlight">
\[objective = \sum_{T} w_t(d_{goal}(t)) || v_t ||_2\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>goal</strong> – goal state/position for robot agent (2).</p></li>
<li><p><strong>optimize_speed</strong> – include cost for zero velocity at goal state.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="mantrap.modules.goal_norm.GoalNormModule.compute_gradient_analytically">
<code class="sig-name descname">compute_gradient_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.goal_norm.GoalNormModule.compute_gradient_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective gradient vector analytically.</p>
<p>While the gradient vector of the objective can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main gradient() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.goal_norm.GoalNormModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.goal_norm.GoalNormModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>Since the objective value computation depends on the ego_trajectory (and the ego goal) only, this
should always hold.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.goal_norm.GoalNormModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.goal_norm.GoalNormModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>To compute the goal-based objective simply take the L2 norm between all positions on the ego trajectory
and the goal. To encounter the fact, that it is more important for the last position (last = position at
the end of the planning horizon) to be close to the goal position than the first position, multiply with
a strictly increasing importance distribution, cubic in this case.</p>
<p>When the goal-velocity is included here, compute the speed as L2 norm per trajectory state. Then weight
the speeds at every time by its distance to the goal, as explained in the description of this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mantrap.modules.baselines.goal_weighted">
<span id="goal-weighted"></span><h3>Goal-Weighted<a class="headerlink" href="#module-mantrap.modules.baselines.goal_weighted" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.baselines.goal_weighted.GoalWeightedModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.baselines.goal_weighted.</code><code class="sig-name descname">GoalWeightedModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">goal</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.baselines.goal_weighted.GoalWeightedModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Objective based on goal distance of every point of planned robot trajectory.</p>
<p>This module merely serves as a baseline comparison for the <cite>GoalMeanModule</cite>, by using a weighted
sum instead of the mean for combining the point-wise objectives. Following the idea that it is
more important for the last point of the trajectory to be close to the goal than the first one,
the larger the trajectory index the larger the weight of the point-wise distance.</p>
<dl class="py method">
<dt id="mantrap.modules.baselines.goal_weighted.GoalWeightedModule.compute_gradient_analytically">
<code class="sig-name descname">compute_gradient_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.baselines.goal_weighted.GoalWeightedModule.compute_gradient_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective gradient vector analytically.</p>
<p>While the gradient vector of the objective can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main gradient() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.baselines.goal_weighted.GoalWeightedModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.baselines.goal_weighted.GoalWeightedModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>To compute the goal-based objective simply take the L2 norm between all positions on the ego trajectory
and the goal. To encounter the fact, that it is more important for the last position (last = position at
the end of the planning horizon) to be close to the goal position than the first position, multiply with
a strictly increasing importance distribution, cubic in this case.</p>
<p>When the goal-velocity is included here, compute the speed as L2 norm per trajectory state. Then weight
the speeds at every time by its distance to the goal, as explained in the description of this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="interaction-driven-objectives">
<h2>Interaction-Driven Objectives<a class="headerlink" href="#interaction-driven-objectives" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-mantrap.modules.prob_interact">
<span id="probability-interaction"></span><h3>Probability Interaction<a class="headerlink" href="#module-mantrap.modules.prob_interact" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.prob_interact.InteractionProbabilityModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.prob_interact.</code><code class="sig-name descname">InteractionProbabilityModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.prob_interact.InteractionProbabilityModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss based on unconditioned probability value in distribution conditioned on ego motion.</p>
<p>The general idea of an interactive objective module is to compare the ado trajectory distributions as if
no ego/robot would be in the scene with the distributions conditioned on the robot trajectory, in order to
drive the robot’s trajectory optimisation to some state in which the ados are (in average) minimally
disturbed by the robots motion. For general ado trajectory probability distributions including multi-modality,
this is not a trivial problem. In fact its is not analytically solved for most multi-modal distributions.
However in the following some common approaches:</p>
<p>1) KL-Divergence: The KL-Divergence expresses the similarity some distribution q with respect to another
distribution p:</p>
<p>While this is a well-defined and  commonly used similarity measure for “simple” distributions for more
complex ones, such as GMM (e.g. as Trajectron’s output) it is not analytically defined. Methods to
approximate the KL-Divergence for GMMs embrace Monte Carlo sampling, optimisation (itself) and several
more which however are not computationally feasible for an online application, especially since the
objective’s gradient has to be computed. Other methods simply the real GMM to a single Gaussian, by a
weighted average over its parameters, which is a) not guaranteed to be a meaningful distribution and
b) looses the advantages of predicting multi-modal distributions in the first place.</p>
<p>Especially for trajectron one could also not use the output distribution, but some intermediate (maybe
simpler distribution) instead, e.g. the latent space, but this one does not depend on the ego trajectory
so cannot be used for its optimisation.</p>
<p>2) Unconditioned path projection: Another approach is to compute (and maximize) the probability of the
mean un-conditioned trajectories (mode-wise) appearing in the conditioned distribution. While it only takes
into account the mean values (and weights) it is very efficient to compute while still taking the full
conditioned distribution into account and has shown to be “optimise-able” in the training of Trajectron.
Since the distributions itself are constant, while the sampled trajectories vary, the objective is also
constant regarding the same scenario, which also improves its “optimise-ability”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>env</strong> – solver’s environment environment for predicting the behaviour without interaction.</p>
</dd>
</dl>
<dl class="py method">
<dt id="mantrap.modules.prob_interact.InteractionProbabilityModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.prob_interact.InteractionProbabilityModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>If the internal environment is itself differentiable with respect to the ego (trajectory) input, the
resulting objective value must have a gradient as well.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.prob_interact.InteractionProbabilityModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.prob_interact.InteractionProbabilityModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mantrap.modules.baselines.acc_interact">
<span id="acceleration-interaction"></span><h3>Acceleration Interaction<a class="headerlink" href="#module-mantrap.modules.baselines.acc_interact" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.baselines.acc_interact.InteractionAccelerationModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.baselines.acc_interact.</code><code class="sig-name descname">InteractionAccelerationModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.baselines.acc_interact.InteractionAccelerationModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss based on accelerational interaction between robot and ados.</p>
<p>As a proxy for interaction based on the acceleration of every ado is computed in a (fictional) scene without an
ego (robot) and compared to the actual occurring accelerations in the scene. As for autonomous driving the
acceleration can be expressed “moving comfort”, since a change in acceleration, especially a sudden change like
strong de-acceleration, decreases the comfort of the agent.</p>
<p>Re-Predicting it every time-step would be more correct, however it would also require a lot more computational
effort (horizon times as much to be exact). Therefore merely the behavior of the ado without ego is computed
that would occur, if the ego is not there from the beginning.</p>
<div class="math notranslate nohighlight">
\[objective = \sum_{T} \sum_{ados} || acc_{t,i} - acc_{t,i}^{wo} ||_2\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>env</strong> – environment for predicting the behaviour without interaction.</p>
</dd>
</dl>
<dl class="py method">
<dt id="mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.distribution_to_acceleration">
<code class="sig-name descname">distribution_to_acceleration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist_dict</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.distributions.distribution.Distribution<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.distribution_to_acceleration" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute ado-wise accelerations from positional distribution dict mean values.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>If the internal environment is itself differentiable with respect to the ego (trajectory) input, the
resulting objective value must have a gradient as well.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.baselines.acc_interact.InteractionAccelerationModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>To compute the objective value first predict the behaviour of all agents in the scene in the planning
horizon, conditioned on the ego trajectory. Then compare the (mode-wise if multi-modal) means of
the previously computed un-conditioned (see initialization) and the conditioned distribution, in
terms of their second derivative, i.e. acceleration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mantrap.modules.baselines.pos_interact">
<span id="position-interaction"></span><h3>Position Interaction<a class="headerlink" href="#module-mantrap.modules.baselines.pos_interact" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.baselines.pos_interact.InteractionPositionModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.baselines.pos_interact.</code><code class="sig-name descname">InteractionPositionModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.baselines.pos_interact.InteractionPositionModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss based on positional interaction between robot and ados.</p>
<p>As a proxy for interaction based on the position of every ado is computed in a (fictional) scene without an
ego (robot) and compared to the actual occurring positions in the scene, as in intuitive measure for the change
the robot’s presence introduces to the scene.</p>
<p>Re-Predicting it every time-step would be more correct, however it would also require a lot more computational
effort (horizon times as much to be exact). Therefore merely the behavior of the ado without ego is computed
that would occur, if the ego is not there from the beginning.</p>
<div class="math notranslate nohighlight">
\[objective = \sum_{T} \sum_{ados} || pos_{t,i} - pos_{t,i}^{wo} ||_2\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>env</strong> – solver’s environment environment for predicting the behaviour without interaction.</p>
</dd>
</dl>
<dl class="py method">
<dt id="mantrap.modules.baselines.pos_interact.InteractionPositionModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.baselines.pos_interact.InteractionPositionModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>If the internal environment is itself differentiable with respect to the ego (trajectory) input, the
resulting objective value must have a gradient as well.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.baselines.pos_interact.InteractionPositionModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.baselines.pos_interact.InteractionPositionModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>To compute the objective value first predict the behaviour of all agents (and modes) in the scene in the
planning horizon, conditioned on the ego trajectory. Then iterate over every ghost in the scene and
find the deviation between the positions of a specific agent at the specific point in time conditioned
on the ego trajectory and unconditioned. Multiply by the weights of the modes, in order to encounter for
difference in importance between these modes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-mantrap.modules.control_limits">
<span id="control-effort-constraints"></span><h2>Control-Effort Constraints<a class="headerlink" href="#module-mantrap.modules.control_limits" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="mantrap.modules.control_limits.ControlLimitModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.control_limits.</code><code class="sig-name descname">ControlLimitModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.control_limits.ControlLimitModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximal control input at every point in time.</p>
<p>For computing this constraint simply the norm of the planned control input is determined and compared to the
maximal agent’s control limit. For 0 &lt; t &lt; T_{planning}:</p>
<div class="math notranslate nohighlight">
\[||u(t)|| &lt; u_{max}\]</div>
<dl class="py method">
<dt id="mantrap.modules.control_limits.ControlLimitModule.compute_jacobian_analytically">
<code class="sig-name descname">compute_jacobian_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.control_limits.ControlLimitModule.compute_jacobian_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Jacobian matrix analytically.</p>
<p>While the Jacobian matrix of the constraint can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main jacobian() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>When the gradient shall be computed with respect to the controls, then computing the gradient analytically
is very straight-forward, by just applying the following formula:</p>
<div class="math notranslate nohighlight">
\[\frac{ d ||u|| }{ du_i } = \frac{u_i}{||u||}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.control_limits.ControlLimitModule.constraint_core">
<code class="sig-name descname">constraint_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.control_limits.ControlLimitModule.constraint_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint value core method.</p>
<p>The max control constraints simply are computed by transforming the given trajectory to control input
(deterministic dynamics). Then take the norm over the “cartesian” axis to get the norm of the
control input at every time-step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.control_limits.ControlLimitModule.constraint_limits">
<code class="sig-name descname">constraint_limits</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">, </span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#mantrap.modules.control_limits.ControlLimitModule.constraint_limits" title="Permalink to this definition">¶</a></dt>
<dd><p>Lower and upper bounds for constraint values.</p>
<p>The boundaries of this constraint depend on the exact implementation of the agent, however most agents
are isotropic, so assuming to have equal control boundaries in both cartesian directions and also
have its lower bound smaller or equal to zero, so that we can simplify the constraint to only have an
upper bound (since the lower bound zero is anyways given and a norm is semi-positive).</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.control_limits.ControlLimitModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.control_limits.ControlLimitModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>Since the ego trajectory directly depends on the controls, the gradient always exists.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="safety-constraints">
<h2>Safety-Constraints<a class="headerlink" href="#safety-constraints" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-mantrap.modules.hj_reachibility">
<span id="hj-reachability"></span><h3>HJ-Reachability<a class="headerlink" href="#module-mantrap.modules.hj_reachibility" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule">
<em class="property">class </em><code class="sig-prename descclassname">mantrap.modules.hj_reachibility.</code><code class="sig-name descname">HJReachabilityModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="environment.html#mantrap.environment.base.graph_based.GraphBasedEnvironment" title="mantrap.environment.base.graph_based.GraphBasedEnvironment">mantrap.environment.base.graph_based.GraphBasedEnvironment</a></span></em>, <em class="sig-param"><span class="n">t_horizon</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">10.0</span></em>, <em class="sig-param"><span class="n">data_file</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'2D.mat'</span></em>, <em class="sig-param"><span class="n">interp_method</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Soft constraint based on Hamilton-Jacobi Reachability.</p>
<p>Use HJ (aka backward) reachability to constraint the ego agent to not become “unsafer” when moving, i.e.
to chose some trajectory so that the backward reachability value function does not become larger. This is
equivalent to a min-max-game between the robot and each pedestrian, in which the pedestrian tries to catch
the ego robot and while the robot tries to avoid the pedestrian. When the value function is negative, it
is provably safe which means no matter what the pedestrian does (regarding safety trying to “catch” the robot is
the worst case) they cannot reach each other.</p>
<p>with <cite>f_{rel}(x, u_R, u_P)</cite> being the system dynamics of the relative state. Since the robot is modelled
as double integrator while all pedestrians are modelled as single integrators, the relative (coupled) systems
state only depends on the relative position as well as the velocity of the robot, not the velocity of the
pedestrian (which is a system input).</p>
<p>The coupled system dynamics then are given as:</p>
<p>Since <cite>sigma</cite> is a slack variable the according weight in the objective function should be comparably large.</p>
<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.compute_jacobian_analytically">
<code class="sig-name descname">compute_jacobian_analytically</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">grad_wrt</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>numpy.ndarray<span class="p">]</span><a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.compute_jacobian_analytically" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Jacobian matrix analytically.</p>
<p>While the Jacobian matrix of the constraint can be computed automatically using PyTorch’s automatic
differentiation package there might be an analytic solution, which is when known for sure more
efficient to compute. Although it is against the convention to use torch representations whenever
possible, this function returns numpy arrays, since the main jacobian() function has to return
a numpy array. Hence, not computing based on numpy arrays would just introduce an un-necessary
<cite>.detach().numpy()</cite>.</p>
<p>In the following we assume that assume that we look for the jacobian with respect to the ego controls,
but to keep this general we will test it at the beginning. However since this module is based on look-up
table interpolated values, we cannot compute the full derivative using torch’s autograd framework only,
as in other modules, therefore if <cite>grad_wrt</cite> is not the controls, an error is raised (since otherwise
autograd would be used and fail).</p>
<p>Since we pre-computed both the value function and its gradient computing the jacobian is quite
straight-forward. Using  the chain rule we get:</p>
<div class="math notranslate nohighlight">
\[\frac{dJ}{du} = \frac{dJ}{dx_{rel}} \frac{dx_{rel}}{du}\]</div>
<p>with dJ/dx_rel being pre-computed we only have to determine dx_rel/du.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>grad_wrt</strong> – vector w.r.t. which the gradient should be determined.</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.constraint_core">
<code class="sig-name descname">constraint_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">enable_auto_grad</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.constraint_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine constraint value core method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
<li><p><strong>enable_auto_grad</strong> – enable auto-grad to allow automatic backpropagation but slowing down
computation (for debugging &amp; testing only).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.constraint_limits">
<code class="sig-name descname">constraint_limits</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">, </span>Optional<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.constraint_limits" title="Permalink to this definition">¶</a></dt>
<dd><p>Lower and upper bounds for constraint values.</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.gradient_condition">
<code class="sig-name descname">gradient_condition</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.gradient_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition for back-propagating through the objective/constraint in order to obtain the
objective’s gradient vector/jacobian (numerically). If returns True and the ego_trajectory
itself requires a gradient, the objective/constraint value, stored from the last computation
(<cite>_current_</cite>-variables) has to require a gradient as well.</p>
<p>The constraint and objective evaluation basically are table-lookups which are in general
not differentiable (although there are approaches to do so, like some kind of function
fitting, but they are not used here).</p>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.objective_core">
<code class="sig-name descname">objective_core</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ego_trajectory</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ado_ids</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">tag</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.objective_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine objective value core method.</p>
<p>Since the module imposes soft constraints on the backward reachability value gradient, the
objective value is introduced by the sum of slack variables, which is represented by
<cite>sigma</cite> in constraint equation above. However soft constraints are dealt with automatically
in the parent optimisation module class, therefore simply return <cite>None</cite> (no additional
objective function) here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ego_trajectory</strong> – planned ego trajectory (t_horizon, 5).</p></li>
<li><p><strong>ado_ids</strong> – ghost ids which should be taken into account for computation.</p></li>
<li><p><strong>tag</strong> – name of optimization call (name of the core).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mantrap.modules.hj_reachibility.HJReachabilityModule.state_relative">
<em class="property">static </em><code class="sig-name descname">state_relative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_r</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">u_r</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">x_ped</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">u_ped</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">dt</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#mantrap.modules.hj_reachibility.HJReachabilityModule.state_relative" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine the relative state and dynamics (see module description):</p>
<p>Since the states of robot and pedestrian as well as the action of the robot are known, at the time
of evaluating the constraint, only the pedestrians controls are unknown. However in HJ reachability
we look for the controls that minimize the value function, by evaluating the value function for
several assignments of <cite>u_ped</cite> and finding the arg-min. In this context this function assumes that
all states as well as the robots control are “unique” while it can handle a whole bunch of
different pedestrian controls and computes the relative state for each of them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_r</strong> – robot’s state (x, y, vx, vy)</p></li>
<li><p><strong>u_r</strong> – robot’s control input (ux, uy).</p></li>
<li><p><strong>x_ped</strong> – pedestrian’s state (px, py, vpx, vpy).</p></li>
<li><p><strong>u_ped</strong> – pedestrian control input  (upx, upy).</p></li>
<li><p><strong>dt</strong> – time-step [s] for applying dynamics on current state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>next state for each pedestrian control input.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Objective and Constraint Modules</a><ul>
<li><a class="reference internal" href="#base-optimization-modules-abstract">Base Optimization Modules (abstract)</a><ul>
<li><a class="reference internal" href="#module-mantrap.modules.base.optimization_module">Base class</a></li>
<li><a class="reference internal" href="#module-mantrap.modules.base.pure_objective">Pure objective</a></li>
<li><a class="reference internal" href="#module-mantrap.modules.base.pure_constraint">Pure constraint</a></li>
</ul>
</li>
<li><a class="reference internal" href="#goal-driven-objectives">Goal-Driven Objectives</a><ul>
<li><a class="reference internal" href="#module-mantrap.modules.goal_norm">Goal-Norm</a></li>
<li><a class="reference internal" href="#module-mantrap.modules.baselines.goal_weighted">Goal-Weighted</a></li>
</ul>
</li>
<li><a class="reference internal" href="#interaction-driven-objectives">Interaction-Driven Objectives</a><ul>
<li><a class="reference internal" href="#module-mantrap.modules.prob_interact">Probability Interaction</a></li>
<li><a class="reference internal" href="#module-mantrap.modules.baselines.acc_interact">Acceleration Interaction</a></li>
<li><a class="reference internal" href="#module-mantrap.modules.baselines.pos_interact">Position Interaction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-mantrap.modules.control_limits">Control-Effort Constraints</a></li>
<li><a class="reference internal" href="#safety-constraints">Safety-Constraints</a><ul>
<li><a class="reference internal" href="#module-mantrap.modules.hj_reachibility">HJ-Reachability</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="solver.html"
                        title="previous chapter">Solver</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="attention.html"
                        title="next chapter">Attention Modules</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/modules.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="attention.html" title="Attention Modules"
             >next</a> |</li>
        <li class="right" >
          <a href="solver.html" title="Solver"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">mantrap 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Objective and Constraint Modules</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Simon Schaefer.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.1.0.
    </div>
  </body>
</html>