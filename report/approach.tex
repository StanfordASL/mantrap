\chapter{Multi-Modal Interaction-Aware Trajectory Optimization}
\label{text:approach}
In this chapter, an overview of the approach is provided. Starting in Section \ref{text:approach/formulation} the problem of socially aware motion planning is formulated formally, including the assumptions made within this project. 
\newline
Section \ref{text:approach/overview} which presents an overview of the full trajectory optimization pipeline. It is shown how the algorithm is built to allow to deal with general graph-like pedestrian behavior prediction models, with multi-modal, probabilistic outputs. Furthermore, the advantages of formulating socially aware motion planning as an optimization problem while utilizing a graph-based prediction model, e.g. deep learning-based models such as the Trajectron \cite{Ivanovic18}, over purely learned \cite{Chen2017} or purely optimization-based \cite{Berg2011} algorithms are illustrated. Finally, it is explained how the usage of a general-purpose, computation-graph based framework such as PyTorch \cite{pytorch} or TensorFlow \cite{tensorflow} can be harnessed for a highly modular, efficient, and versatile implementation.
\newline
The exact formulation of the optimization problem is further explained in Section \ref{text:approach/objective} and \ref{text:approach/constraint}. Beginning with the objective function both the goal-driven and the interaction-driven parts are illustrated, together with a derivation of their gradients. Furthermore, several designs of the specific objective function are discussed. The subsequent section addresses the design of the constraints used. Likewise, several constraint function designs are compared. 
\newline
To use the system in real-world applications it must comply with several requirements. While some of these have been tackled by the optimization design, e.g. feasibility of the control limitations of the robot or safety regarding robot-human interaction, the system underlies runtime limits. To achieve this goal several runtime improvements have been implemented, which are described in Section \ref{text:approach/runtime}.


\section{Problem Formulation}
\label{text:approach/formulation}
In this work we are interested in finding the optimal trajectory for a robot navigating among pedestrians on the two-dimensional plane. Let $\x_t = (x_t, y_t, \dot{x}_t, \dot{y}_t) \in \mathbb{R}^4 $ be the position and velocity of the robot, also referred as $ego$, at time $t$ and $\x_{0:N}$ a trajectory over multiple states $(\x_0, \x_1, \x_2, \hdots, \x_N)$. Within this work the robot is assumed to have double integrator dynamics. With control input $\u_t = (u_{x, t}, u_{y, t}) \in \mathbb{R}^2$ and system dynamics $f(\cdot)$, we have: 

\begin{align}
\ddx_t &= \u_t \\
\dx_t &= f(\x_t, \u_t)
\label{eq:robot_dynamics}
\end{align}

For further simplification the robot's dynamics are assumed to be deterministic.
\newline
In general each pedestrian's (also referred as $ado$) trajectory is probabilistic and multimodal. Thereby,  let $\xped[k]_t = \boldsymbol{\tilde{\xi}_t^k}$ be the positional distribution of pedestrian $k$ at time $t$, with mean $\boldsymbol{\tilde{\mu}_t^k}$, variance $\boldsymbol{\tilde{\Sigma}_t^k}$ and mode-weights vector $\boldsymbol{\tilde{\pi}_t^k}$. 

\begin{equation}
\xped[k]_t \sim \boldsymbol{\tilde{\xi}_t^k}(\boldsymbol{\tilde{\mu}_t^k}, \boldsymbol{\tilde{\Sigma}_t^k}, \boldsymbol{\tilde{\pi}_t^k})    
\end{equation}

Similar to the robot the pedestrians are modeled as single point masses, both underlying speed bounds defined by the $L_1$ norm of their velocities. 
\newline
The pedestrian's trajectories are predicted using some model $\tilde{\Phi}$ which is assumed to be known. As described above in general for some pedestrian $k$ the model $\tilde{\Phi}_k$ outputs a multi-modal distribution over the next positions $\xped[k]_{t:t+T}$ conditioned on the trajectory of the robot $\x_{0:t}$, the trajectory of every other pedestrian in the scene $\xped[j]_{0:t} (j \neq k)$ and the trajectory of the pedestrian $k$ itself, i.e.\ $\xped[k]_{0:t}$. Moreover, the function $\tilde{\Phi}$ is generally not shared overall pedestrian, but individually for each one.

\begin{equation}
\xped[k]_{t:t+T} = \tilde{\Phi}_k(\x_{0:t}, \xped[0]_{0:t}, \hdots, \xped[K]_{0:t})\end{equation}

Furthermore both the robot and the pedestrians underly constraints for their minimal and maximal control effort. Thus, the sets of feasible control inputs $
\mathcal{U}$ and $\mathcal{\tilde{U}}$ respectively, are defined using the $L_1$-norm:

\begin{align}
\mathcal{U} &= \{\u | \u \in \mathbb{R}^2, ||\u||_1 \leq u_{max}\} \\
\mathcal{\tilde{U}} &= \{\uped[] | \uped[] \in \mathbb{R}^2, ||\uped[]||_1 \leq \tilde{u}_{max}\} 
\label{eq:controls_bounds}
\end{align}
 
All actions are assumed to take place in a free-space, two-dimensional environment. 
\newline
Within project \project I want to find a robot trajectory $\x_{0:T}$ over some discrete-time horizon $N$ that trade-offs between minimizing the travel time from its current state to some goal state in $\mathcal{X}_f = \{\boldsymbol{g} | \boldsymbol{g} \in \mathcal{X} \}$ on the one side and the interference with the pedestrians in the scene on the other side, concerning its dynamic as well as safety boundaries. For further simplification, a perfect knowledge about the current and all past states of surrounding agents $\xped[k]_{0:t} \forall k \in [0, K]$ is assumed. 

\section{System Overview}
\label{text:approach/overview}
As shown in Figure \ref{img:information_flow} the problem can be divided into several subproblems, which also can be seen as modules of a trajectory optimization problem and therefore can be formulated independently from each other. 

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=\imgwidth]{images/placeholder.png}
\caption{Information-Flow-Diagram}
\label{img:information_flow}
\end{center}
\end{figure}

Formally, the solution to this problem can be represented as the following optimization problem (compare Problem \ref{eq:formulation}). In this work the initial time $t_0 = 0$ and the final time $t_f = T \cdot \Delta t$ is used for simple notation, although not required in general \cite{Wachter2006}. \\

\begin{problem} General \project optimization problem
\begin{equation}
\min_{\u_{0:T-1}} \quad w_{goal} J_{goal}(\x_{0:T}) + w_{int} \sum_{k=0}^M \mathbb{E}_{\xped[k]_{0:T}}[J_{int}(\x_{0:T}, \xped[j]_{0:T})]
\end{equation}
\begin{align}
\textrm{s.t. } \quad & \x_{t+1} = f(\x_t, \u_t) & \forall t \in [0, T - 1] \\
& \xped[k] = \tilde{\Phi}_k(\x_{0:t}, \xped[i]_{0:t}) & \forall k \in [0, K], \forall t \in [0, T]\\
& g_{safety}(\x_{0:T}, \xped[k]_{0:T}) \leq 0 & \forall k \in [0, K] \\
& \x_t \in \mathcal{X} & \forall t \in [0, T]\\
& \u_t \in \mathcal{U} & \forall t \in [0, T]\\
& \x_0 \in \mathcal{X}_0
\end{align} 
\label{eq:formulation}
\end{problem}

The objective function is a weighted sum of a goad-driven $J_{goal}(\cdot)$ and some interaction-driven term $J_{int}(\cdot)$, which are further explained in Section \ref{text:approach/objective}. The constraints are a combination of dynamics constraints, safety constraints as well as initial and final state restrictions, which are discussed in Section \ref{text:approach/constraint}. Note that the terminal state $\x_T$ of the planned trajectory is not constrained to be in the terminal set $\mathcal{X}_f$. As stated in chapter \ref{text:introduction} within this project the safety and undisturbed gait of pedestrians is considered to be more important than reaching the goal state time-optimally. While the goal-driven objective $J_{goal}(\cdot)$ introduces an incentive to approach the goal state, constraining the terminal state to be in the terminal set would informally speaking, remove the possibility of detouring to not interfere a pedestrians movement. 

%todo: nonzero inequality \& inequality Jacobian, Hessian, number of variables, number of constraints 

\subsubsection{Transcription Method} 
Trajectory optimization is a wide field with many different methodologies. Though the area can be roughly broken down into two categories, shooting and collocation \cite{Kelly2017}.\footnote{There are several other directions of separation possible such as the direct vs indirect methods, but I will focus on shooting vs collocation here. Further information about the taxonomy of trajectory optimization can be found in \cite{Kelly2017} and \cite{Chai2020}.} Shooting optimizes for the control inputs and unrolls them using a simulation environment to compute objective and constraint. Thereby the dynamics constraint $x = f(x, u)$ is intrinsically enforced. In comparison, collocation uses all controls and (!) states as decision variables, while constraining the system dynamics, and tries to solve the \ac{NLP} by approximating some function (e.g.\ Lagrange polynomials in orthogonal collocation). Due to the linear and cheap to compute dynamics, the availability of a simulation engine tightly bound to the optimization and since the constraints acting on both the path $\x_{0:T}$ itself and the controls $\u_{0:T}$ are comparably "simple", as illustrated in Section \ref{text:approach/constraint}, shooting is used within this project. Therefore the trajectory is split up into several segments, one for each discrete discretization time step, which makes solving problem \ref{eq:formulation} easier to be solved and more robust (multiple shooting) \cite{Betts1998}.

\subsubsection{Nonlinear optimization Solver} 
Since no further assumptions about the pedestrian trajectory prediction model $\tilde{\Phi}$ have been made, the optimization is non-linear and especially non-convex in general. As shown in \cite{Gould2003}\cite{Parkinson2018}\cite{Freund2004} there are a bunch of algorithms to deal with general non-linear optimization problems, such as line-search, trust-region, interior-point, generalized-reduced-gradient or sequential-quadratic-programming methods as well as combinations of these such as LOQO. However, not all of them apply to constrained problems such as Problem \ref{eq:formulation}. For constrained optimization problems \ac{SQP} and \ac{IPM} are the most popular ones, both having their advantages and drawbacks. While \ac{SQP} usually require fewer solver iterations and thus fewer function calls, they scale poorly with the number of constraints and do not guarantee that intermediate results are feasible \cite{Dehdari2013}\cite{Parkinson2018}. Although this can be an advantage in the case of computationally expensive constraints, it also leads to an infeasible solution when the algorithm is stopped for convergence. Additionally, compared to \ac{IPM} the computational time required by the solver itself is usually larger (e.g. as demonstrated in \cite{Dehdari2013}).
\newline
In project \project safety is induced by constraint, thus obtaining a feasible solution is crucial, also if the algorithm might be aborted before convergence due to runtime constraints. For this reason, an interior-point method has been used within the project. The interior-point method \ac{IPOPT} \cite{Wachter2006} has shown to be applicable in many robotics applications, and has shown to be valuable even in case of very tough runtime constraints such as solving the feedforward commands in high-performance automated driving at 50 Hz in \cite{Spielberge2019} or motion planning for legged robotics \cite{Winkler2018}. There it has been used in this project as well\footnote{From today's point of view it turned out, after tweaking the performance of the optimization core as best as possible, it turns out that the number of objective function calls is the bottleneck of the algorithm. Therefore comparing the capacity of the interior-point solver such as \ac{IPOPT} with \ac{SQP} solvers such as \ac{GuSTO} remains for future work.}.

\subsubsection{Implementation Details} 
The algorithm has been implemented in Python 3.7 using PyTorch \cite{pytorch}. Next to executing computations highly efficiently by vectorization and batching PyTorch's automatic differentiation framework allows computing gradients at low computational cost as well as modular, i.e.\ without the need to explicitly define its closed form. This is the core of prediction-based optimization, enabling to define objectives and constraints (such as $J_{int}$), which depend on a complex graph-based computation, and still being able to derive their gradient without costly and inaccurate numerical approximations. 
\newline 
Furthermore, the algorithm has been implemented highly modular, allowing to easily use pre-defined simulation environments, objective, constraint functions, or new solvers and switch between them without much knowledge about the underlying implementation. To pave the way for further projects based on this project it has been widely documented using Sphinx\footnote{Automated code documentation: https://www.sphinx-doc.org/en/master/}, for further information please visit the \href{https://simon-schaefer.github.io/mantrap/}{project's website}.  
\newline
The system's integrity has been verified by roughly 500 unit- and integration tests, secured over the code developed by the continuous integration framework CircleCI\footnote{Automated testing framework: https://circleci.com} and CodeCov\footnote{Testing coverage reports: https://codecov.io}.

\section{Objective Function Design}
\label{text:approach/objective}

\subsection{Goal Objective}
\label{text:approach/objective/goal}
The goal objective gives an incentive for the optimizer to choose a solution that targets the goal state. It simply consists of the squared L2-norm between each robot trajectory point and the goal state $\boldsymbol{g}$, normalized over the full planning horizon $N$:

\begin{equation}
J_{goal}(\x_{0:T}) = \frac{1}{N} \sum_{t = 0}^N (\x_t - \boldsymbol{g})^2
\label{eq:goal_unweighted}
\end{equation}

By normalization, the cost is independent of the length of the planning horizon $T$ and thus allows us to use the same weight $w_{goal}$ for different planning horizons.

\subsubsection{Horizon weighting}
Intuitively, as discussed in Chapter \ref{text:introduction} for socially aware navigation socially-aware objectives should be higher weighted than traditional control effort or travel time objectives. This is especially true at the beginning of the planning horizon. For this reason the a horizon dependent weighting $\lambda_t$ is introduced into the stage cost of the goal objective, which is small at the beginning of the horizon and large at its end: 

\begin{equation}
J_{goal}(\x_{0:T}) = \frac{1}{N} \sum_{t = 0}^N \lambda_t (\x_t - \boldsymbol{g})^2
\label{eq:goal_weighted}
\end{equation}

As shown later on this modification empowers a fast convergence to evasive movements of the robot, when necessary to avoid un-safe situations, while properties of $J_{goal}(\cdot)$ such as most importantly convexity remain unchanged. In Table \ref{table:goal_horizon_weighting} the convergence speed of both the "un-weighted" and the "weighted" objective formulation are compared over 100 runs in a simplified setup, with no pedestrian in the scene and random assignments of the robot's initial and goat state. Weighting the cost terms non-uniformly over the horizon enables finding "trade-offs" of a locally higher cost for a faster global convergence such as gaining speed in a non-goal-direction at the beginning of the horizon but leads to a smaller cost at the end of it. 

\begin{table}[!ht]
\begin{center}
\begin{tabular}{c|c|c}
 & Weighted & Un-Weighted \\
\hline
Avg. number of solving iterations & 9.58 & 9.64 \\
\hline
Avg. $95 \%$ decay of objective value & 5.86 & 6.64 \\
\end{tabular}
\caption{Comparison of key performance parameter of the optimization using either the "un-weighted" (Equation \ref{eq:goal_unweighted}) or the "weighted" (Equation  \ref{eq:goal_weighted}) goal objective formulation over 100 runs in a simplified environment setup. For further details please have a look into the example notebook: \href{https://github.com/simon-schaefer/mantrap/blob/master/examples/modules/goal.ipynb}{examples/modules/goal}.}.
\label{table:goal_horizon_weighting}
\end{center}
\end{table}

\subsubsection{Gradient}
Since the goal objective $J_{goal}(\x_{0:T})$ is only a function of the robot's planned trajectory and the goal state, its jacobian can be derived without further knowledge of the pedestrian prediction model, merely using the (known) robot dynamics. As described in Section \ref{text:approach/overview} the robot controls are optimized. Hence by applying the chain rule we get: 

\begin{equation}
\nabla J_{goal} = \pd{J_{goal}}{\u_{0:T-1}} = \pd{J_{goal}}{\x_{0:T}} \cdot \pd{\x_{0:T}}{\u_{0:T-1}}
\end{equation}

As demonstrated, the goal-objectives gradient can be derived by multiplying the objectives gradient with respect to the robot's trajectory with the gradient of the robot's trajectory with respect to its control inputs. Since the goal-objective directly depends on the trajectory, deriving the first term is straight-forward to derive. The second term $\delta \x_{0:T} / \delta \u_{0:T-1}$ is not trivial in general, because of the iterative structure of rolling out state trajectories based on dynamics and as the robot's dynamics $f(\cdot)$ can be arbitrary, however as described in Section \ref{text:approach/formulation} double integrator dynamics are assumed for the robot, so that the whole trajectory $\x_{0:T}$ can be expressed as function of the initial state $\x_0$ and the control inputs $\u_{0:T-1}$ only, as shown in equation \ref{eq:dynamics_stacked}. Then the term $\delta \x_{0:T} / \delta \u_{0:T-1}$ simplifies to a constant term:

\begin{align}
\pd{J_{goal}}{\x_{0:T}} &= \pd{}{\x_{0:T}} \frac{1}{N} \sum_{t = 0}^N (\x_t - \boldsymbol{g})^2 \\
&= \frac{2}{T} \begin{bmatrix} (\x_1 - \boldsymbol{g}) & \hdots & (\x_T - \boldsymbol{g}) \end{bmatrix}^T
\end{align}
\begin{align}
\pd{\x_{0:T}}{\u_{0:T-1}} &= \pd{}{\u_{0:T-1}} \begin{bmatrix} A \x_0 \\ A_n \x_0 + B_n \u_{0:T-1} \end{bmatrix} \\
&= \begin{bmatrix} \boldsymbol{0}_{n \times m} \\ B_n \end{bmatrix}
\label{eq:goal_gradient_dynamics}
\end{align}

with $A_n, B_n$ the stacked state-space description matrices as described in Section \ref{text:approach/runtime/unrolling}. 
\newline
Overall the goal objective and its gradient are very efficient, cheap to compute, having linear complexity with the length of the planning horizon $T$, and being independent of the number of pedestrians. Furthermore, it is strictly convex, which improves the optimization convergence speed. Therefore it is quite valuable for warm-starting the optimization algorithm, as further explained in Section \ref{text:approach/runtime/warm_starting}.

%todo: final speed objective

\subsection{Interaction Objective}
\label{text:approach/objective/interactive}
The interaction between robot and pedestrian itself is an abstract quantity and can thus hardly be used for optimization itself. To approach this problem in the following we consider a scene with the robot facing only one pedestrian, to then generalize the developed concept to interactions with multiple pedestrians.  
\newline
While it is hard to find a measure for the interaction between the robot and the pedestrian in the scene when regarding the problem in general, it can be simplified when a) focussing on one of the interacting agents and b) define the measure to vanish its value. Under these conditions, the problem can be re-formulated as decreasing the disturbance the robot induces on the pedestrian, which is a lot simpler to quantify than the abstract concept of interaction. To do so the un-conditioned\footnote{For the sake of brevity the term "un-conditioned" means not depend on the robot's state. However, the pedestrian's trajectory prediction is of course still conditioned on its state history as well as the states and state history of the other pedestrians in the scene, as described in Section \ref{text:approach/formulation}.} pedestrian's trajectory distribution $\xpedwo[]_{0:T}$ is computed, i.e. the distribution that would occur if no robot would be in the scene, and then compared to its actual conditioned trajectory distribution $\xped[]_{0:T}$.\footnote{When the prediction model requires the input of a robot trajectory, e.g. as an "input format" requirement of a neural network-based model, predicting the un-conditioned trajectory distribution might not be straight-forward. Using a re-trained un-conditioned model is not an option since factors causing a different distribution independent from the robot's trajectory might come into play. Thus, within the project a "pseudo"-robot is used which is located very far away from any pedestrian, hence minimizing its effect on the pedestrian's behavior.}

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}

    \node[inner sep=0pt] (pedwo) at (-3,1)
    {\includegraphics[width=.05\textwidth]{images/walking.png}};    
    \draw [dotted, ultra thick, name path=A] (pedwo) to[out=180, in=0] node[above] {$\xpedwo[k]$} (-8, 1);
    

    \node[inner sep=0pt] (pedw) at (-3,-1)
    {\includegraphics[width=.05\textwidth]{images/walking.png}};
    \node[inner sep=0pt] (robot) at (-7,-1)
    {\includegraphics[width=.05\textwidth]{images/robot.png}};
    \draw [ultra thick, name path=B] (pedw) to[out=180, in=10] node[below, sloped] {$\xped[k]$}(-8,-3);
    
    \draw[thick, decorate, decoration={brace, amplitude=20pt}] (-1.5,2) -- (-1.5,-2);

    \node[inner sep=0pt] (ped) at (5,0.5)
    {\includegraphics[width=.05\textwidth]{images/walking.png}};
    
    \draw [dotted, ultra thick, name path=A] (ped) to[out=180, in=0] node[above] {$\xpedwo[k]$} (0, 0.5);
    \draw [ultra thick, name path=B] (ped) to[out=180, in=10] node[below, sloped] {$\xped[k]$}(0,-1.5);
        
    \tikzfillbetween[of=A and B]{blue, opacity=0.2};
    \node[] (D) at (1, -0.3){$D_{int}$};
    
\end{tikzpicture}
\end{center}
\caption{Interactive measure in case of deterministic and uni-modal pedestrian trajectory predictions, which trivially is the area enclosed by the un-conditioned (upper) and the conditioned (middle) trajectory.}
\label{img:ado_w_wo_distance_trajectory}
\end{figure}

If the pedestrian's trajectory prediction would be deterministic and uni-modal this measure simply breaks down to the distance between both trajectories which is the area enclosed by both trajectories in continuous time, as shown in Figure \ref{img:ado_w_wo_distance_trajectory}, or a sum of distance per time-step in discrete time. For probabilistic and multi-modal predictions computing the distance between both distributions is more difficult, especially when demands such as computational cost and differentiability (to be used in an optimization) have to be factored in. 

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}

    \node[inner sep=0pt] (ped) at (5,0)
    {\includegraphics[width=.05\textwidth]{images/walking.png}};
    \node[inner sep=0pt] (robot) at (0,0)
    {\includegraphics[width=.05\textwidth]{images/robot.png}};
       
    \draw [dotted, ultra thick, name path=A] (ped) to[out=180, in=0] (0, 2) node[above, sloped] {$\xpedwo[k]$}  to[out=180, in=0] (-4, 0);
    
    \draw [ultra thick, name path=B] (ped) to[out=180, in=10] (0,-2) node[below, sloped] {$\xped[k]$} to[out=180, in=0] (-4, 0);
    
\end{tikzpicture}
\end{center}
\caption{Interactive measure in case of deterministic and uni-modal pedestrian trajectory predictions, which trivially is the area enclosed by the un-conditioned (upper left) and the conditioned (upper right) trajectory.}
\label{img:int_acceleration_reason}
\end{figure}

The correlation between the acceleration carried out on a passenger and its comfort is widely known, e.g. for the driving use case \cite{Hoberock1976}. Therefore assuming that the same measure applies for correlation between the acceleration the pedestrian itself has to exert (e.g. to evade a dynamic obstacle) and its comfort is likely. Therefore, instead of contrasting the positional distributions ($\xpedwo[]_{0:T}$, $\xped[]_{0:T}$) it might be valuable to use the accelerational distributions ($\ddxpedwo[]_{0:T}$, $\ddxped[]_{0:T}$). Figure \ref{img:int_acceleration_reason} shows a possible scenario, in which the presence of the robot affects the pedestrian such that the trajectory prediction is mirrored. When the robot is static and when no other pedestrian is close, both trajectories are equally safe (if the robot is static)  and "comfortable" for the pedestrian and are equal in length, so there is no reason to chose one above the other. However, due to the large enclosed area, a purely position-based distance metric would be non-zero by far, while an acceleration-based distance metric would be zero since the velocities of the pedestrian-only change their sign, not their absolute value.

\subsubsection{Kullback-Leibler Divergence}
A commonly used metric for expressing the distance between two distributions is the Kullback-Leibler Divergence $D_{KL}$, which determines the distance between  some distribution $q$ and another distribution $p$ as:

\begin{equation}
D_{KL} = \int_x q(x) log \frac{q(x)}{p(x)} dx    
\end{equation}

While $D_{KL}$ is a well-defined, is capable to be used in optimization procedures and is therefore commonly used in many applications, such as generative deep learning models \cite{Goodfellow2014}\cite{Salzmann2020} (similarly the Jenson-Shannon Divergence), it is not analytically defined for some "complex" distributions such as \ac{GMM}, which is the output distribution format of Trajectron \cite{Ivanovic2018}. Methods to approximate the KL-Divergence for \ac{GMM}s have been discussed in \cite{Cui2015} and embrace Monte Carlo sampling, signature quadratic form distance \cite{Beecks2011} and several more which however are not computationally feasible for an online application, especially since its gradient has to be computed. Other methods simplify the real \ac{GMM} to a single Gaussian, by a weighted average over its parameters, which is not guaranteed to be a meaningful distribution and loses the advantages of predicting multi-modal distributions in the first place. 
\newline
Regarding the Trajectron \cite{Ivanovic2018} as prediction model, some intermediate distribution might be used for comparison instead of the output distribution, such as the categorical distribution in its latent space\footnote{In fact, the Trajectron's latent space could not be used as a basis for the interactive objective function anyway, since it does not depend on the robot's trajectory. However, it might be used to assess the similarity between scenarios, which will be discussed in Section \ref{text:approach/runtime/warm_starting}.}. Although this approach might give rise to use widely used distance measures such as $D_{KL}$ it would impede tractability and generality of the overall framework, as it would have to be re-defined for every other prediction model. 

\subsubsection{Sample-Wise Distance}
Next to taking the full trajectory distribution into account instead of the distance between the un-conditioned $\xpedwo[]_{0:T}$ and the conditioned trajectory distribution $\xped[]_{0:T}$ can be approximated by computing the expected value over sample pairs. Then the distance measure breaks down to a weighted sum over L2-norms for each discrete time-step within the time horizon and for every trajectory pair, which are efficient to compute. 

\begin{equation}
D_{int}^{sp} = \sum_{samples} \sum_T ||\xpedwo[s]_t - \xped[s]_t||_2
\end{equation}

Also using samples instead of the full distribution allows us to efficiently compute the velocity and accelerations of the pedestrian at each predicted time-step numerically, using central difference expressions. 

\begin{equation}
D_{int}^{sa} = \sum_{samples} \sum_T ||\ddxpedwo[s]_t - \ddxped[s]_t||_2
\end{equation}

%todo: acceleration-based distance measure

\subsubsection{Trajectory Projection}
Unconditioned path projection: Another approach is to compute (and maximize) the probability of the mean conditioned trajectories (mode-wise) appearing in the unconditioned distribution. While it only takes into account the mean values (and weights) it is very efficient to compute while still taking the full conditioned distribution into account and has shown to be "optimize-able" in the training of Trajectron. Since the distributions itself are constant, while the sampled trajectories vary, the objective is also constant regarding the same scenario, which also improves its "optimize-ability".

 
%todo: have a look at how Trajectron is built and learned, having in mind that the objective function should be transferable to other models as well; 

%todo: comparison position/acceleration distance-based to probabilistic objective function (in favor of distance-based => takes into account acceleration and therefore "effort/comfort", but only mean ... in favor of probabilistic => takes into account full distribution, similar to model loss function to "fits" the model)


\section{Constraint Function Design}
\label{text:approach/constraint}

\subsection{Dynamics Constraints}
\label{text:approach/constraint/dynamics}
The dynamics constraints subside all constraints in problem \ref{eq:formulation} that are not directly related to safety, i.e. 

\begin{align}
\label{eq:constraint_f}
&\x_{t+1} = f(\x_t, \u_t) \qquad& \forall t \in [0, T - 1] \\
\label{eq:constraint_x}
&\x_t \in \mathcal{X} & \forall t \in [0, T]\\
\label{eq:constraint_u}
&\u_t \in \mathcal{U} & \forall t \in [0, T]\\
\label{eq:constraint_x0}
&\x_0 \in \mathcal{X}_0
\end{align}

Using the shooting trajectory optimization paradigm the decision variables are the robot's control inputs  $\u_t \in \mathcal{U}$ so that the states $\x_t$ are obtained by unrolling the controls starting at some initial state $\x_0 \in \mathcal{X}_0$ and iteratively using the robot's dynamics $f(\cdot)$. \ac{IPOPT} on the other side solves a general \ac{NLP} of the form \cite{Wachter2006} \\

\begin{problem}{General IPOPT problem formulation}
\begin{align}
\min_{x \in \mathbb{R}^n} \quad & f(x) \\
\textrm{s.t. } \quad & g^L \leq g(x) \leq g^U \\
& x^L \leq x \leq x^U 
\end{align}
\label{eq:formulation_ipopt}
\end{problem}

As indicated in Section \ref{text:approach/formulation} the bounds of the controls $\u_t$ have a shape, as the decision variable $x$ in problem \ref{eq:formulation_ipopt}. Therefore \ref{eq:constraint_u} is implicitly posed, without further ado, just by using the robot's control input bounds as bounds of the decision variable. Also the constraints \ref{eq:constraint_f} and  \ref{eq:constraint_x0} are satisfied by the problem design, using the shooting method, leaving merely the constraint \ref{eq:constraint_x} to be explicitly defined. The state $\x$ of the robot incorporates both, its position and its velocity. While the prediction models, objectives and constraints depend only  relative measures regarding the agent's positions and therefore the positional subset of $\mathcal{X}$ can be safely assumed as being unbounded ($\mathcal{X}_{pos} = \mathbb{R}^2$). Due to the speed boundaries that are imposed on the robot ($||v||_1 \leq v_{max}$, comp. Section \ref{text:approach/formulation}), in order for the solution to be feasible a maximal speed constraint has to be established:

\begin{equation}
\x_t \in \mathcal{X} \Rightarrow -v_{max} \leq g_{v_{max}}(\x_t) = \dot{\x}_t \leq v_{max} \quad \forall t \in [0, T]
\label{eq:constraint_v_max}
\end{equation}

Computing the jacobian for constraint \ref{eq:constraint_v_max} is straight-forward using chain rule and exploiting the linear robot dynamics (as above when deriving the goal objective's gradient in equation \ref{eq:goal_gradient_dynamics}):  

\begin{align}
\nabla g_{v_{max}} &= \pd{g_{v_{max}}}{\u_{0:T-1}} = \pd{g_{v_{max}}}{\x_{0:T}} \cdot \pd{\x_{0:T}}{\u_{0:T-1}} \\
\Rightarrow \pd{g_{v_{max}}}{\x_{0:T}} &= \begin{bmatrix} \pd{g_{v_{max}}^1}{\x_{0:T}} & \hdots & \pd{g_{v_{max}}^T}{\x_{0:T}}\end{bmatrix}^T  \\
&= \begin{bmatrix} 
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & \hdots & 0 \\ 
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & \hdots & 0 \\  
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & \hdots & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & \hdots & 0 \\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \hdots & 1 \end{bmatrix} \\
\Rightarrow \pd{\x_{0:T}}{\u_{0:T-1}} &= \begin{bmatrix} \mathbf{0}_{n \times m} \\ B_n \end{bmatrix}
\end{align}
 

\subsection{Reachability Constraint}
\label{text:approach/constraint/reachability}

% however they follow single integrator dynamics. As pointed out in \cite{Ivanovic18} this is an intuitive choice "as a person’s movements are all position-changing, e.g. walking increases position along a direction, running does so faster". Other standard models for pedestrian dynamics such as Social Forces \cite{Helbling1995} however regard the pedestrian to be a double integrator, not a single integrator, and describe the forces acting on it introduced by other pedestrians, obstacles, etc. Having a reasonable fast reaction time and a large maximal acceleration in comparison to the robot both of these descriptions converge, so that the single integrator model is a good choice nonetheless.\footnote{As discussed in chapter \ref{text:experiments} the modular implementation allows us to use different pedestrian dynamics. When testing against other prediction environments non-single integrator dynamics are used, but most analysis described in this report relates to the single integrator model.} 

% todo: constraint formulation (e.g. min-distance constraints split to be more accurate or summed to compute Jacobian faster)
% todo: Quellen: neural network representation of value function to make it differentiable (Karen: reachability, Kyle David Julian: network representation to make sure all the corner cases are met)
% todo: turns out being a linear constraint (see 1D graph)
%todo: special case => current state is infeasible, then convert to cost of the high weight

% Reachability Meeting
% Is max_u min_d the same as min_d max_u, so conditioning the disturbance on the input instead of the other way around ? ==> minimax-theorem, depending on function ==> factor out grad V times f
% Constraining value function > 0 instead of gradient since gradient always worse (pedestrian faster than robot) ? => yes
% Coupling: Just the intersection as weakly coupled system with combining element the robot’s state ? => yes
% How to deal with multiple control actions ? Just constraint initial control action ? => just initial control step with horizon = planning horizon or longer
% LWPR: infinite runtime ==> linear interpolation (like Karen’s paper) ==> buffer around V > 0 like V > 0.2 to account for interpolation errors

\section{Runtime optimization}
\label{text:approach/runtime}

\subsection{Efficient Trajectory Unrolling}
\label{text:approach/runtime/unrolling}
One of the most promising directions for decreasing the runtime of a trajectory optimization algorithm is to decrease the runtime of the objective and constraints evaluation as well as their gradients. As shown in sections \ref{text:approach/objective} and \ref{text:approach/constraint} the majority of these optimization modules depends on the robot's trajectory $X_R$, rather than on its control inputs $U_R$. However since control inputs are optimized, as described in Section \ref{text:approach/overview}, a computationally efficient transformation from controls and initial state to the trajectory is key for making the trajectory optimization real-time feasible.
\newline
Fortunately, we assumed that the robot follows double integrator dynamics, which are linear and markovian. Hence, they can be expressed as the following: 

\begin{equation}
\x_{t+1} = A \x_t + B \u_t
\label{eq:dynamics}
\end{equation}

\begin{minipage}{0.5\textwidth}
$$A = \begin{bmatrix} 1 & 0 & \delta t & 0 \\ 0 & 1 & 0 & \delta t \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1\end{bmatrix}$$
\end{minipage}
\begin{minipage}{0.5\textwidth}
$$B = \begin{bmatrix} 0 & 0 & \delta t & 0 \\ 0 & 0 & 0 & \delta t \end{bmatrix}$$
\end{minipage}

Due to the linear (not linearized !) dynamics $\delta t = \Delta t$ can be safely used. In order to fully "unroll" a trajectory the linear dynamic equation \ref{eq:dynamics} would be to be applied iteratively for the length of the trajectory. Since the dynamics themselves are linear (not just a first-order approximation) this computation can be further batched and on this way, speeded up. In fact the full trajectory can be derived merely based on the initial state $\x_0$ and the control input matrix $\u_{0:T}$, as shown in the following:

\begin{align}
\x_1 &= A \x_0 + B \ u_0 \\
\x_2 &= A \x_0 + B \ u_1 = A^2 \x_0 + A B \ u_0 + B \ u_1\\ 
\hdots &= \hdots \\
\begin{bmatrix} \x_1 \\ \x_2 \\ \vdots \\ \x_n \end{bmatrix} &= \underbrace{\begin{bmatrix} A \\ A^2 \\ \vdots \\ A^n \end{bmatrix}}_{\substack{A_n}} \x_0 + \underbrace{\begin{bmatrix} B & 0 & \hdots & \hdots & 0 \\ AB & B & 0 & \hdots & 0 \\ \hdots & \hdots & \hdots & \hdots & \hdots \\ A^{n-1} B & A^{n-2} B & \hdots & \hdots & B \end{bmatrix}}_{\substack{B_n}} \begin{bmatrix} \u_0 \\ \u_1 \\ \vdots \\ \u_{n-1} \end{bmatrix}
\end{align}

In summary, we get the following (also linear) expression for computing the full robot trajectory at once. As demonstrated in \href{https://github.com/simon-schaefer/mantrap/blob/master/examples/tools/timing.ipynb}{examples/tools/timing} using the fully batched formulation speeds up the trajectory "unrolling" by about a factor of 30.  

\begin{equation}
\x_{1:n} = A_n \x_0 + B_n \u_{0:T-1}
\label{eq:dynamics_stacked}
\end{equation}

\subsection{Warm Starting}
\label{text:approach/runtime/warm_starting}
It is widely known that warm starting an optimization can be very beneficial for its convergence speed for several optimization algorithms, e.g. shown in \cite{Banerjee2020} for \ac{GuSTO} or for \ac{IPOPT} in \cite{Shahzad2010}, \cite{John2008} or \cite{Spielberge2019}.
\newline
Within project \project the algorithm has been warm-started by solving the optimization problem posed in problem \ref{eq:formulation} while ignoring all objectives and constraints that relate to pedestrians, i.e. by solving the following optimization problem: \\

\begin{problem}{Simplified \project optimization problem for warm-starting}
\begin{align}
\min_{\u_{0:T-1}} \quad & J_{goal}(\x_{0:T}) \\
\textrm{s.t. } \quad & \x_{t+1} = f(\x_t, \u_t) & \forall t \in [0, T - 1] \\
& \x \in \mathcal{X} & \forall t \in [0, T]\\
& \u_t \in \mathcal{U} & \forall t \in [0, T]\\
& \x_0 \in \mathcal{X}_0
\end{align} 
\label{eq:formulation_warm_starting}
\end{problem}

Since the simplified optimization problem in problem \ref{eq:formulation_warm_starting} does not depend on the pedestrian dynamics model $\tilde{\Phi}$ it is much easier and more efficient to solve, being a convex quadratic program. \\

%todo: pre-computation warm-starting since going straight is often not a good choice
%todo: influence of the number of pedestrians in encoding on initial cost

% Warm-start using pre-computation (similarity by trajectron latent space vs manual encoding) ==> discrete latent space so could be total mess (perturbation sensitivity ??) ==> see jupyter notebook evaluation and reminder

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}

    \node (R) at (0, 0) [circle, shade, draw] {Robot};
    \node (G) at (8, 4) [circle, shade, draw] {Goal};
    \node (P1) at (2, 3) [circle, fill=orange, draw] {$P_1$};
    \node (P2) at (8, 1) [circle, fill=yellow, draw] {$P_2$};
    
    \tkzDefPointBy[projection=onto R--G](P1)  \tkzGetPoint{P1m}
    \tkzDefPointBy[projection=onto R--G](P2)  \tkzGetPoint{P2m}
    
    \draw[->, dotted, very thick] (R) to node[above] {} (G);
    \draw (P1m) -- (P1) node[midway, sloped, above] {$\mu_{P1}$};
    \draw (R) -- (P1m) node[midway, sloped, above] {$\eta_{P1}$};
    \draw (P2m) -- (P2) node[midway, sloped, above] {$\mu_{P2}$};
    \draw (R) -- (P2m) node[midway, sloped, below] {$\eta_{P1}$};
    
\end{tikzpicture}
\end{center}
\label{img:robot_goal_encoding}
\end{figure}

%Does the pre-computed set contain every possible scenario? No, but just warm-start so not required, there will be a constrained optimization afterward anyway

\subsection{Attention}
\label{text:approach/runtime/filtering}
