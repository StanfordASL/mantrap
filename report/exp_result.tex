\section{Experimental Setup}
\label{text:experiments/setup}
All experiments are performed in simulation, mainly due to the practical implications of the COVID-19 outbreak, and the theoretical facilities of enabling fair, unbiased comparisons. As previously explained in Section \ref{text:experiments/metrics}, there is no unique way of evaluating the performance of a planning algorithm. This intricacy primarily is caused by the highly dynamic, stochastic and various behavior of human gait and social (non-verbal) interaction. For further complication, the "theory of mind", the basis of socially-aware human behavior (see Chapter \ref{text:related}), is able to adapt to the current situation as well as learn from previously experienced similar situations. Fairly comparing two planning algorithms would therefore require the same set of human participants, but without knowledge gain over several testing episodes. This is clearly not possible. In contrary, performing the experiments in simulation allows to compare under same initial conditions and simulation dynamics, as the same model can be applied in parallel without correlation between independent experiments. 
\newline
However, ultimately the trajectory optimization algorithm has to work under real conditions. Therefore, analog experiments have been planned, but finally could not be executed due to the implications of the COVID-19 outbreak. Show-Casing the performance of the algorithm in real-world therefore remain for future work.

\paragraph{Simulation engine}
The purposed algorithm is tightly-coupled with a pedestrian prediction algorithm. Using the same model for trajectory optimization and simulation might therefore introduce the planning algorithm with an unrealistic gain of knowledge about the actual system dynamics, which are of course unknown in real-world scenario. Therefore, a completely independent (or at least parametrically different) prediction model must be used for forwarding the simulation. \ac{SGAN} \cite{Gupta2018} is a state-of-the-art generative, \ac{GAN}-based neural network for pedestrian trajectory prediction. Similarly to the Trajectron model \cite{Salzmann2020}, it generates trajectories conditioned on all agents in the scene, and within a single prediction step over the full prediction horizon. However, it is not conditioned on the robot trajectory, and therefore merely used for an independent, but accurate prediction model to evaluate the trajectory optimization algorithm in simulation. While \ac{SGAN} can thus not be used to inform the trajectory optimization, it is well-suited as independent simulation model for evaluation. 

\paragraph{Simulation parameters}
For accurately render a real-world scenario not only the agents dynamics, but also the state boundaries such as velocity and acceleration limits have to be defined. Bohannon et alt. \cite{Bohannon1997} determine the mean maximum gait speed by age and sex, and conclude that the overall maximum average speed is $253.3 cm/s$ (men in their twenties). To model the limited amount of control energy at the robot's disposal as well as its usually smaller (maximal) speed\footnote{As an example see the CrowdBots of the EU Horizon project: \href{http://crowdbot.eu/our-bots/}{http://crowdbot.eu/our-bots/}.} , compared to pedestrians, the robot has a maximum speed of $200 cm/s$ and acceleration of $200 cm/s^2$. The same parameter set informs the bounds of the coupled dynamics of the robot-pedestrian system of the \ac{HJR}-safety-constraint. The asymmetric distribution of maximal speed values between pedestrians and robot makes the interaction especially safe, since the optimization has to come up with an efficient, but reasonable risk-less solution trajectory, as the safety constraint becomes infeasible over time in any case ($\Vrel_{HJR}(t) < 0$ for some $t < \infty$).

\paragraph{Platform} 
All tests have been performed on a 2.3GHz MacBook Pro 2018. Due to the intrinsic stochasticity of the problem, the tests have been evaluated in a Monte-Carlo fashion, averaged over usually 40 repetitions with the same initial conditions (when not stated otherwise). To prevent the evaluation from falsifying measurements of runtime, specific metrics are logged online, to be evaluated after finalization of the test.