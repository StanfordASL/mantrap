\section{Experimental Results}
\label{text:experiments/results}

\subsection{Experimental Setup}
- walking speed \cite{Bohannon1997}

\subsection{Unit Experiments}
\subsubsection{Horizon Weighting for Goal Objective Function}
In Table \ref{table:goal_horizon_weighting}, the convergence speed of both the "unweighted" \ref{eq:goal_unweighted} and the "weighted" \ref{eq:goal_weighted} objective formulation are compared over 100 runs in a simplified setup, with no pedestrian in the scene and random assignments of the robot's initial and goat state. Weighting the cost terms non-uniformly over the horizon enables finding "trade-offs" of a locally higher cost for faster global convergence, such as gaining speed in a non-goal-direction at the beginning of the horizon but leads to a smaller cost at the end of it.

\begin{table}[!ht]
\begin{center}
\begin{tabular}{c|c|c}
\bf Goal Objective & \bf MSI & \bf M95OD \\
\hline
Weighted & 9.58 & 5.86 \\
\hline
Un-Weighted & 9.64 & 6.64 \\
\end{tabular}
\caption{Comparison of key performance parameter of the optimization using either the "un-weighted" (Equation \ref{eq:goal_unweighted}) or the "weighted" (Equation  \ref{eq:goal_weighted}) goal objective formulation over 100 runs in a simplified environment setup. For further details please have a look into the example notebook: \href{https://github.com/simon-schaefer/mantrap/blob/master/examples/module_goal.ipynb}{examples/module\_goal}.}
\label{table:goal_horizon_weighting}
\end{center}
\end{table}

\subsubsection{Alternatives to. Interactive Objective Function}
Next to the interactive objective function $J_{int}(\cdot)$, described in Section \ref{text:approach/objective/interactive}, there are several other ways to formulate it. Instead of taking the full trajectory distribution into account for computing the distance measure between the unconditioned $\distwo[]$ and the conditioned trajectory distribution $\dist[]$, it can be approximated by computing the expected value over sample pairs. Consequently, the distance measure breaks down to a weighted sum over $L_2$-norms for each discrete time-step within the time horizon and for every trajectory pair, which are efficient to compute.

\begin{equation}
D_{int}^{sp} = \sum_{samples} \sum_T ||\xpedwo[s]_t - \xped[s]_t||_2
\end{equation}

The samples are deterministic trajectories and can be numerically differentiated efficiently, using central difference expressions. As previously described, it might be more meaningful to compare velocity or acceleration instead of positions.

\begin{align}
J_{int, sa}^{k} &= \sum_{samples} \sum_T ||\ddxpedwo[s]_t - \ddxped[s]_t||_2	 \\
J_{int, sv}^{k} &= \sum_{samples} \sum_T ||\dxpedwo[s]_t - \dxped[s]_t||_2	 \\
J_{int, sp}^{k} &= \sum_{samples} \sum_T ||\xpedwo[s]_t - \xped[s]_t||_2
\label{eq:interaction_diff}	
\end{align}

Although quite intuitive, it turns out that a sample-wise objective is hard to optimize. This has two predominant reasons: Firstly, it intrinsically relies on a trade-off between computational feasibility (to compute many times per second for an online optimization) and capability to capture the properties of the underlying real distributions sufficiently well. Secondly, when randomly drawn samples are used, stochasticity is introduced into the objective function, which might lead to a different objective value even when evaluated with the same input. When the distribution's means are used instead, the distribution's uncertainty is disregarded.
\newline
In the following, the projection-probability-based interactive loss function in Equation \ref{eq:objective_interact_prob} is compared against the alternative difference-based objectives, presented above in \ref{eq:interaction_diff}. Due to the previously explained limitations instead of sampled trajectories, the mean trajectory is merely being used, thereby neglecting the prediction's variance. For the comparison, a Monte Carlo simulation is used for a set of custom defined scenarios. Due to the uncertainty evolved in the environment dynamics, the performance is evaluated over 10 test runs each. A meaningful comparison should exclude external factors as best as possible, therefore to exclude interactive effects occurring due to other parts of the optimization, other than the compared objective functions, the safety constraint is not used in this experiment. \\ 

\begin{table}[!ht]
\begin{center}
\begin{tabular}{c|c|c|c|c|c|c}
\bf Interactive Objective & \bf MPE & \bf RTD & \bf RCE & \bf ETT & \bf TGD & \bf MSD \\
\hline
diff\_pos & 0.33 & 0.99 & 0.32 & 0.0 & 0.24 & 0.94 \\
\hline
diff\_vel & 0.29 & 0.98 & 0.51 & 0.0 & 0.26 & 1.16 \\
\hline
diff\_acc & 0.21 & 0.98 & 0.55 & 0.0 & 0.27 & 1.24 \\ 
\hline
\rowcolor{baseline_color}
without & 0.31 & 1.0 & 0.27 & 0.0 & 0.23 & 1.08 \\ 
\hline
\rowcolor{our_color}
projection & 0.01 & 0.92 & 0.79 & 0.8 & 0.39 & 1.44 
\end{tabular}
\end{center}
\label{table:interactive_objective}
\end{table}

The experiments show the effect of the interactive objective function: It trades off the required travel time to reach the goal position with increasing the safety and "ease" of the interaction by reducing the pedestrian's efforts and increasing the minimum separation distance. Figure \ref{img:interactive_comp} displays the solution trajectories for an exemplary scenario.  The projection-probability objective accomplishes to increase distance when necessary but gets on track afterward. In opposition, the alternative formulations either fail to establish a sufficient distance to the pedestrian (comp. the second or third image, associated with diff\_pos and diff\_vel) or cannot recover afterward as in the case for the acceleration difference objective.

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=\textwidth]{images/inter_comp_multi.png}
\captionof{figure}{Example solution trajectories for different interactive objective function, beginning from the left: projection, diff\_pos, diff\_vel, diff\_acc, without interactive loss function}
\label{img:interactive_comp}
\end{center}
\end{figure}

\subsubsection{HJR Value Function Approximation}
The necessity as well as the feasibility of approximating the \ac{HJR} value function has been motivated in Section \ref{text:approach/constraint/safety}. In the following several approximation methods are compared and evaluated.
\newline 
Figure \ref{img:hj_approx_bar} shows the logarithmic approximation error for several pre-computed grid sizes and using linear (as in \cite{Leung2020})) and Nearest Neighbor interpolation methods. LWPR (not shown here) has been tested as well but turned out to be infeasible for a large number of grid points.\footnote{For more information about the implementation of the LWPR value function approximation see \href{https://github.com/simon-schaefer/HJReachibility}{HJ-Reachability Toolbox} on GitHub.} For computing the error metric, the value function has been computed on a dense grid exactly, and point-wise compared with the grid interpolated approximations. While linear interpolation widely outperforms Nearest Neighbor, as expected, the absolute error is tiny. As displayed in Figure \ref{img:hj_approx_hist}, the interpolation error is not uniform over all joint state axes, but larger for positional axes (which likely is due to the larger amount of non-linearity in position compared to velocity directions, compare Figure \ref{img:hj_value_function}). Therefore, the number of grid points have not been equally distributed over the axes, but biased to the positional axes (interior), while keeping the overall size of the grid constant.

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.45\textwidth]{images/hj_bar_linear.png}
\includegraphics[width=0.45\textwidth]{images/hj_bar_nearest.png}
\caption{Logarithmic value function approximation error using linear (left) and nearest neighbor (right) interpolation methods based on various pre-computed grid sizes (small < interior < medium)}
\label{img:hj_approx_bar}
\end{center}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=\imgwidth]{images/hj_hist_linear.png}
\caption{Absolute error distribution over joint system state axes using linear interpolation based on various pre-computed grid sizes (small < interior < medium)}
\label{img:hj_approx_hist}
\end{center}
\end{figure}

\subsubsection{Warm-Starting Methods}
\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}

    \node (R) at (0, 0) [circle, shade, draw] {Robot};
    \node (G) at (8, 4) [circle, shade, draw] {Goal};
    \node (P1) at (2, 3) [circle, fill=orange, draw] {$P_1$};
    \node (P2) at (8, 1) [circle, fill=yellow, draw] {$P_2$};
    
    \tkzDefPointBy[projection=onto R--G](P1)  \tkzGetPoint{P1m}
    \tkzDefPointBy[projection=onto R--G](P2)  \tkzGetPoint{P2m}
    
    \draw[->, dotted, very thick] (R) to node[above] {} (G);
    \draw (P1m) -- (P1) node[midway, sloped, above] {$\mu_{P1}$};
    \draw (R) -- (P1m) node[midway, sloped, above] {$\eta_{P1}$};
    \draw (P2m) -- (P2) node[midway, sloped, above] {$\mu_{P2}$};
    \draw (R) -- (P2m) node[midway, sloped, below] {$\eta_{P1}$};
    
\end{tikzpicture}
\end{center}
\label{img:robot_goal_encoding}
\end{figure}

%Does the pre-computed set contain every possible scenario? No, but just warm-start so not required, there will be a constrained optimization afterward anyway

\subsection{Integration Experiments}
